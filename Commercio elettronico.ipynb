{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commercio elettronico\n",
    "Corso seguito nell'anno 2014-2015 a Ca'Foscari dal professor Claudio Silvestri\n",
    "\n",
    "## Prima esercitazione\n",
    "Lo scopo di questa esercitazione è la creazione di una collezione di documenti di testo a partire da un insieme di pagine web di interesse.\n",
    "\n",
    "* scegliere un sito web\n",
    "\n",
    "* ricerca su Google limitata ad un sito (es: \"site:www.ansa.it parlamento\")\n",
    "\n",
    "* parsing dei risultati per trovare gli url delle pagine trovate (attenzione: ci sono anche altri link da non considerare come quelli alla copia in cache). Suggerimento: disabilitare Javascript sul browser e guardare il contenuto del risultato di una ricerca\n",
    "\n",
    "* get delle pagine individuate (salvare su file e non scaricare nuovamente se esiste già)\n",
    "\n",
    "* parsing e salvataggio di testo ed eventuali attributi delle pagine\n",
    "\n",
    "* creare il lessico, aggiornare un contatore delle occorrenze di ciascun termine (totali e numero di documenti distinti). Ordinare per frequenza descrescente, esportare i dati e tracciare dei grafici (x:rank, y: frequenza) utilizzando sia scale lineari che logaritmiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'BeautifulSoup'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d0ddae7d06d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlxml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'BeautifulSoup'"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from urllib.request import FancyURLopener\n",
    "from bs4 import BeautifulSoup\n",
    "from google import search\n",
    "import requests\n",
    "\n",
    "SESSION = requests.Session()\n",
    "GOOGLE_SEARCH_STRING = \"site:www.repubblica.it + politica OR crisi OR calcio OR articolo OR article\"\n",
    "NUMERORISULTATI = 1\n",
    "WAITINGTIME = 2  # in secondi\n",
    "QUERYGOOGLE = '//h3[@class=\"r\"]/a/@href'\n",
    "QUERYSITO = '//*[@itemprop=\"articleBody\"]/text()'\n",
    "\n",
    "\n",
    "# ####################################################\n",
    "\n",
    "article_url=search(GOOGLE_SEARCH_STRING, stop=NUMERORISULTATI, pause=WAITINGTIME)\n",
    "print(article_url)\n",
    "for url in article_url:\n",
    "    html_page = urllib.request.urlopen(url)\n",
    "    html_string = html_page.read()\n",
    "    converted = BeautifulSoup.UnicodeDammit(html_string, isHTML=True)\n",
    "    if not converted.str:\n",
    "        print(\"\")\n",
    "    print(converted.str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seconda esercitazione: content based recommender\n",
    "Content based recommender:\n",
    "\n",
    "* costruire il vector space model per la collezione di testi create nelle scorse lezioni (oppure utilizzare i testi delle notizie Ansa resi disponibili)\n",
    "  * cold start: scegliere un documento e trovare i documenti simili (coseno)\n",
    "  * warm start: scegliere alcuni documenti di vostro interesse e generare dei suggerimenti basati sui contenuti dei documenti scelti  (coseno) \n",
    "\n",
    "###suggerimenti:\n",
    "\n",
    " * utilizzare un array associativo per gestire il lessico ed associare un codice numerico a ciascun termine\n",
    " * il lessico ed il vector space model possono essere salvati e riutilizzati (sono validi fino a che non cambia il contenuto della collezione)\n",
    " \n",
    "###Altre attività (facoltative):\n",
    "\n",
    " * provare con una misura di distanza diversa\n",
    " * utilizzare i contatore delle occorrenze di ciascun termine e numero di documenti per termine per calcolare TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terza esercitazione: MongoDB\n",
    "Preliminari:\n",
    "\n",
    "* installare MongoDB (attenzione: per i PC del laboratorio è necessario specificare la directory da utilizzare per i dati)\n",
    "* fare alcuni inserimenti e ricerche (http://docs.mongodb.org/manual/tutorial/insert-documents/)\n",
    "* installare pymongo (attenzione: per i PC del laboratorio è necessario utilizzare l'opzione --user di pip)\n",
    "* seguire il tutorial pymongo (http://api.mongodb.org/python/current/tutorial.html)\n",
    "* importare i testi delle esercitazioni precedenti (utilizzare pymongo)\n",
    "* creare un indice testuale (http://docs.mongodb.org/manual/core/index-text/, http://docs.mongodb.org/manual/tutorial/create-text-index-on-multiple-fields/) \n",
    "* fare alcune ricerche semplici e composte (http://docs.mongodb.org/manual/reference/operator/query/text/, http://docs.mongodb.org/manual/reference/operator/query/text/#text-operator-text-score)\n",
    "\n",
    "###Esercitazione:\n",
    "\n",
    "* utilizzare map/reduce per trovare le parole più frequenti\n",
    "* utilizzare map reduce per estrarre il lessico, il modello dei documenti (e le posting lists per la parte opzionale) \n",
    "* rappresentare gli utenti, i testi da loro letti, il modello vettoriale del utente\n",
    "* integrazione del text based recommender sviluppato per l'esercitazione 2\n",
    "\n",
    "###Opzionale:\n",
    "\n",
    "* integrazione esercitazione 2bis\n",
    "* utilizzare le posting list per effettuare delle ricerche testuali\n",
    "* confrontare i risultati delle ricerche effettuate utilizzando le posting list e quelli ottenuti utilizzando le funzioni di ricerca testuale di MongoDB\n",
    "* i risultati delle ricerche di MongoDB possono essere  ordinati per  'text score'. Come potremmo implementare una funzionalità simile utilizzando le posting list ed i modelli di documento?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Quarta esercitazione: Twitter\n",
    "\n",
    "* Installare twython (utilizzare \"pip ... --user .... \" in laboratorio) https://github.com/ryanmcgrath/twython\n",
    "* creare un account su Twitter\n",
    "* seguire l'esempio riportato in https://twython.readthedocs.org/en/latest/usage/streaming_api.html\n",
    "* espandere l'esempio filtrando per locazione (v. Twitter streaming API)\n",
    "* stampare periodicamente le 10 parole più frequenti nei Tweet in Veneto (nel rettangolo che contiene il Veneto)\n",
    "* stampare periodicamente le 10 parole più frequenti nei Tweet che contengono la parola Venezia/Venice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}